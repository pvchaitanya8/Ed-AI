{
    "questions": [
        {
            "question": "What is the time complexity of finding an element in a sorted array using binary search?",
            "options": ["A. O(1)", "B. O(log n)", "C. O(n)", "D. O(n^2)"],
            "answer": "B. O(log n)",
            "explanation": "Binary search repeatedly divides the search space in half, resulting in logarithmic time complexity.",
            "incorrect_explanation": {
                "A": "O(1) is incorrect because binary search divides the space repeatedly.",
                "C": "O(n) is for linear search, not binary search.",
                "D": "O(n^2) is higher than expected for binary search."
            }
        },
        {
            "question": "What is the time complexity of bubble sort?",
            "options": ["A. O(1)", "B. O(log n)", "C. O(n)", "D. O(n^2)"],
            "answer": "D. O(n^2)",
            "explanation": "Bubble sort compares and swaps adjacent elements repeatedly, leading to quadratic time complexity.",
            "incorrect_explanation": {
                "A": "Bubble sort involves multiple comparisons and cannot be done in constant time.",
                "B": "O(log n) is a lower complexity, incorrect for bubble sort.",
                "C": "O(n) is too low for bubble sort."
            }
        },
        {
            "question": "What is the time complexity of merge sort?",
            "options": ["A. O(1)", "B. O(log n)", "C. O(n)", "D. O(n log n)"],
            "answer": "D. O(n log n)",
            "explanation": "Merge sort divides the array into halves and sorts recursively, giving O(n log n) time complexity.",
            "incorrect_explanation": {
                "A": "Cannot be constant time since it divides and merges.",
                "B": "O(log n) is too low for merge sort.",
                "C": "O(n) is too low for merge sort."
            }
        },
        {
            "question": "What is the time complexity of finding the minimum element in an unsorted array?",
            "options": ["A. O(1)", "B. O(log n)", "C. O(n)", "D. O(n^2)"],
            "answer": "C. O(n)",
            "explanation": "You need to scan the entire array, which results in linear time complexity.",
            "incorrect_explanation": {
                "A": "Constant time is not possible since you must scan the array.",
                "B": "O(log n) would be for searching in a sorted array.",
                "D": "O(n^2) is too high for finding the minimum."
            }
        },
        {
            "question": "What is the time complexity of inserting an element at the end of a dynamic array (assuming sufficient capacity)?",
            "options": ["A. O(1)", "B. O(n)", "C. O(log n)", "D. O(n^2)"],
            "answer": "A. O(1)",
            "explanation": "Inserting at the end of a dynamic array is constant-time if there's capacity.",
            "incorrect_explanation": {
                "B": "Shifting elements or resizing would require O(n).",
                "C": "Binary search complexity doesn't apply here.",
                "D": "O(n^2) is unrelated to this operation."
            }
        },
        {
            "question": "What is the time complexity of finding the maximum element in a sorted array?",
            "options": ["A. O(1)", "B. O(log n)", "C. O(n)", "D. O(n^2)"],
            "answer": "A. O(1)",
            "explanation": "In a sorted array, the maximum element is always at the end, so it can be accessed in constant time.",
            "incorrect_explanation": {
              "B. O(log n)": "This would be the case if the array were unsorted and you needed to use binary search.",
              "C. O(n)": "This would be the case if you were searching for an arbitrary element in a sorted array.",
              "D. O(n^2)": "This is a higher time complexity than what is typically associated with finding the maximum element in a sorted array."
            }
        },
        {
            "question": "What is the time complexity of searching for an element in a binary search tree?",
            "options": ["A. O(1)", "B. O(log n)", "C. O(n)", "D. O(n^2)"],
            "answer": "B. O(log n)",
            "explanation": "Binary search trees are balanced structures that allow for efficient searching in logarithmic time.",
            "incorrect_explanation": {
              "A. O(1)": "This would imply that searching in a binary search tree is always constant time, which is not the case.",
              "C. O(n)": "This would be the case for a linear search or an unbalanced binary search tree.",
              "D. O(n^2)": "This is a higher time complexity than what is typically associated with searching in a balanced binary search tree."
            }
        },
        {
            "question": "What is the time complexity of inserting an element into a balanced binary search tree?",
            "options": ["A. O(1)", "B. O(log n)", "C. O(n)", "D. O(n^2)"],
            "answer": "B. O(log n)",
            "explanation": "Inserting an element into a balanced binary search tree involves maintaining balance, which can be done in logarithmic time.",
            "incorrect_explanation": {
              "A. O(1)": "Inserting into a balanced binary search tree involves maintaining balance, which cannot be done in constant time.",
              "C. O(n)": "This would be the case for an unbalanced binary search tree.",
              "D. O(n^2)": "This is a higher time complexity than what is typically associated with inserting into a balanced binary search tree."
            }
        },
        {
            "question": "What is the time complexity of finding the minimum element in a min heap?",
            "options": ["A. O(1)", "B. O(log n)", "C. O(n)", "D. O(n^2)"],
            "answer": "A. O(1)",
            "explanation": "In a min heap, the minimum element is always at the root, so it can be accessed in constant time.",
            "incorrect_explanation": {
              "B. O(log n)": "This would be the case if you were searching for an arbitrary element in the heap.",
              "C. O(n)": "This would be the case if the heap were unbalanced or if you were searching for an element that is not the minimum.",
              "D. O(n^2)": "This is a higher time complexity than what is typically associated with finding the minimum element in a min heap."
            }
        },
        {
            "question": "What is the time complexity of finding the maximum element in a max heap?",
            "options": [ "A. O(1)", "B. O(log n)", "C. O(n)", "D. O(n^2)"],
            "answer": "A. O(1)",
            "explanation": "In a max heap, the maximum element is always at the root, so it can be accessed in constant time.",
            "incorrect_explanation": {
              "B. O(log n)": "This would be the case if you were searching for an arbitrary element in the heap.",
              "C. O(n)": "This would be the case if the heap were unbalanced or if you were searching for an element that is not the maximum.",
              "D. O(n^2)": "This is a higher time complexity than what is typically associated with finding the maximum element in a max heap."
            }
        },
        {
            "question": "What is the time complexity to access an element at a specific index in an array (0-based indexing)?",
            "options": ["A. O(1)", "B. O(n)", "C. O(log n)", "D. O(n^2)"],
            "answer": "A. O(1)",
            "explanation": "Accessing an element at a specific index in an array is a constant-time operation, as arrays provide direct access to any element using the index.",
            "incorrect_explanation": {
              "B": "O(n): This would be the time complexity for scanning through the array.",
              "C": "O(log n): This would be for searching in a sorted array using binary search, not for access.",
              "D": "O(n^2): This is typically for nested loops and not for accessing an element."
            }
        },
        {
            "question": "Given an unsorted array, what is the time complexity of finding the maximum element?",
            "options": ["A. O(1)", "B. O(n)", "C. O(log n)", "D. O(n^2)"],
            "answer": "B. O(n)",
            "explanation": "To find the maximum element in an unsorted array, we need to scan through the entire array, resulting in a linear time complexity of O(n).",
            "incorrect_explanation": {
              "A": "O(1): Scanning the array for the maximum element cannot be done in constant time.",
              "C": "O(log n): This time complexity would apply if the array were sorted, and we used binary search.",
              "D": "O(n^2): This is typically for operations involving nested loops, not for finding the maximum."
            }
        },
        {
            "question": "What will be the result of the following pseudo-code? arr = [10, 20, 30, 40, 50] n = length(arr) sum = 0 for i from 0 to n-1: sum = sum + arr[i] return sum",
            "options": ["A. 150", "B. 140", "C. 160", "D. 120"],
            "answer": "A. 150",
            "explanation": "The pseudo-code iterates through all the elements of the array [10, 20, 30, 40, 50] and adds them up. The sum is 10 + 20 + 30 + 40 + 50 = 150.",
            "incorrect_explanation": {
              "B": "140: Incorrect calculation.",
              "C": "160: Incorrect calculation.",
              "D": "120: Incorrect calculation."
            }
        },
        {
            "question": "What is the output of the following pseudo-code? arr = [2, 4, 6, 8] arr[2] = arr[2] * 2 return arr[2]",
            "options": ["A. 6", "B. 12", "C. 8", "D. 4"],
            "answer": "B. 12",
            "explanation": "The element at index 2 (arr[2] = 6) is multiplied by 2, so arr[2] becomes 12, which is then returned.",
            "incorrect_explanation": {
              "A": "6: The original value of arr[2], before the multiplication.",
              "C": "8: Incorrect, no such value is used.",
              "D": "4: Incorrect, this is unrelated to the specific index used."
            }
        },
        {
            "question": "What is the time complexity of inserting an element at the end of a dynamic array (assuming sufficient capacity)?",
            "options": ["A. O(1)", "B. O(n)", "C. O(log n)", "D. O(n^2)"],
            "answer": "A. O(1)",
            "explanation": "Inserting an element at the end of a dynamic array is an O(1) operation if there is enough capacity. If the array is full, it may need resizing, which would affect time complexity in that case.",
            "incorrect_explanation": {
              "B": "O(n): This applies when shifting elements in an array or resizing when it's full.",
              "C": "O(log n): This is typically for binary search, not insertion.",
              "D": "O(n^2): Unrelated to this operation."
            }
        },
        {
            "question": "Given the following pseudo-code, what value will arr[3] hold after execution? arr = [1, 2, 3, 4, 5] for i from 0 to 3: arr[i] = arr[i] * 2",
            "options": ["A. 8", "B. 10", "C. 6", "D. 4"],
            "answer": "A. 8",
            "explanation": "The loop runs for i = 0 to i = 3, multiplying elements at indices 0, 1, 2, 3 by 2. So arr[3] changes from 4 to 4 * 2 = 8.",
            "incorrect_explanation": {
              "B": "10: Incorrect calculation for the wrong index.",
              "C": "6: This would be arr[2], not arr[3].",
              "D": "4: This is the original value of arr[3] before the multiplication."
            }
        },
        {
            "question": "How many elements are present in an array arr = [5, 10, 15, 20, 25]?",
            "options": ["A. 3", "B. 4", "C. 5", "D. 6"],
            "answer": "C. 5",
            "explanation": "The array contains 5 elements: [5, 10, 15, 20, 25].",
            "incorrect_explanation": {
              "A": "3: Incorrect count.",
              "B": "4: Incorrect count.",
              "D": "6: Incorrect count."
            }
        },
        {
            "question": "What is the time complexity of reversing an array?",
            "options": ["A. O(1)", "B. O(log n)", "C. O(n)", "D. O(n^2)"],
            "answer": "C. O(n)",
            "explanation": "To reverse an array, you must iterate through the entire array, swapping elements, which takes linear time O(n).",
            "incorrect_explanation": {
              "A": "O(1): Constant time would mean no iteration, which is not possible.",
              "B": "O(log n): This applies to logarithmic operations like binary search, not array reversal.",
              "D": "O(n^2): This would apply to nested loops, which isn't necessary for reversal."
            }
        },
        {
            "question": "In a 1D array, which operation is most efficient?",
            "options": ["A. Accessing an element", "B. Inserting at the beginning", "C. Searching for an element", "D. Deleting an element from the middle"],
            "answer": "A. Accessing an element",
            "explanation": "Accessing an element in an array is done in constant time O(1). Other operations, such as inserting or deleting, may involve shifting elements and have higher time complexity.",
            "incorrect_explanation": {
              "B": "Inserting at the beginning: Requires shifting all elements, which is O(n).",
              "C": "Searching for an element: This can take O(n) in an unsorted array.",
              "D": "Deleting from the middle: Requires shifting elements, also O(n)."
            }
        },
        {
            "question": "What will be the value of arr[1] after executing the following pseudo-code? arr = [3, 6, 9] arr[1] = arr[1] + arr[2]",
            "options": ["A. 15", "B. 12", "C. 9", "D. 6"],
            "answer": "B. 12",
            "explanation": "Initially, arr[1] = 6 and arr[2] = 9. The statement arr[1] = arr[1] + arr[2] results in arr[1] = 6 + 9 = 12.",
            "incorrect_explanation": {
              "A": "15: Incorrect addition.",
              "C": "9: This is arr[2], not arr[1].",
              "D": "6: This is the original value of arr[1], before the addition."
            }
        },
        {
            "question": "What is the time complexity of inserting a new node at the head of a singly linked list?",
            "options": ["A. O(1)", "B. O(n)", "C. O(log n)", "D. O(n^2)"],
            "answer": "A. O(1)",
            "explanation": "Inserting a new node at the head of a singly linked list requires constant time because we just need to adjust the head pointer to point to the new node.",
            "incorrect_options": {
              "B. O(n)": "This would be the case for inserting at the tail or at an arbitrary position if the list is not doubly linked.",
              "C. O(log n)": "Logarithmic time complexity is usually associated with binary search, not linked list operations.",
              "D. O(n^2)": "This is incorrect; no nested loops or complex operations are involved."
            }
        },
        {
            "question": "What is the worst-case time complexity of searching for an element in an unsorted singly linked list?",
            "options": ["A. O(1)", "B. O(log n)", "C. O(n)", "D. O(n^2)"],
            "answer": "C. O(n)",
            "explanation": "In the worst case, you may need to traverse the entire linked list to find the element, resulting in linear time complexity.",
            "incorrect_options": {
              "A. O(1)": "Constant time is only possible if the element is at the head.",
              "B. O(log n)": "This time complexity is for binary search, which isn't applicable to linked lists.",
              "D. O(n^2)": "This would be for algorithms involving nested loops, which is not the case here."
            }
        },
        {
            "question": "What is the output of the following pseudo-code, given the input linked list: 10 → 20 → 30 → 40 → 50?\nfunction reversePrint(node):\n    if node == null:\n        return\n    reversePrint(node.next)\n    print(node.data)",
            "options": ["A. 10 20 30 40 50", "B. 50 40 30 20 10", "C. null", "D. Compilation error"],
            "answer": "B. 50 40 30 20 10",
            "explanation": "This pseudo-code uses recursion to traverse the linked list and prints the data after reaching the end, resulting in reverse order printing.",
            "incorrect_options": {
              "A. 10 20 30 40 50": "This would be the output for a normal traversal, not a reverse traversal.",
              "C. null": "The function doesn't return null, it prints values.",
              "D. Compilation error": "The code will compile and run successfully."
            }
        },
        {
            "question": "What is the space complexity of reversing a singly linked list using an iterative approach?",
            "options": ["A. O(n)", "B. O(1)", "C. O(log n)", "D. O(n^2)"],
            "answer": "B. O(1)",
            "explanation": "Reversing a singly linked list iteratively only requires a constant amount of extra space to store a few pointers (prev, current, next), making the space complexity O(1).",
            "incorrect_options": {
              "A. O(n)": "This would be the case if a new list or recursive call stack was created, which isn't required in the iterative approach.",
              "C. O(log n)": "This time complexity applies to recursive approaches with logarithmic depth, but not here.",
              "D. O(n^2)": "No quadratic space complexity is involved."
            }
        },
        {
            "question": "In a circular linked list, what condition indicates that you have completed traversing the entire list?",
            "options": ["A. When the next pointer is null.", "B. When the head pointer is reached again.", "C. When the tail node is reached.", "D. When the data of the node is equal to the value you're searching for."],
            "answer": "B. When the head pointer is reached again.",
            "explanation": "In a circular linked list, the last node points back to the head. Traversal is complete when you return to the head node.",
            "incorrect_options": {
              "A. When the next pointer is null": "This applies to a singly linked list, not a circular linked list.",
              "C. When the tail node is reached": "There is no 'tail' in a circular linked list; it loops back to the head.",
              "D. When the data of the node is equal to the value you're searching for": "This is a condition for searching, not traversal."
            }
        },
        {
            "question": "What is the time complexity of deleting a node from the end of a singly linked list when only the head pointer is given?",
            "options": ["A. O(1)", "B. O(n)", "C. O(log n)", "D. O(n^2)"],
            "answer": "B. O(n)",
            "explanation": "To delete the last node, you need to traverse the entire list to find the second-last node, making the time complexity O(n).",
            "incorrect_options": {
              "A. O(1)": "This would be true if you had a pointer to the last node and its previous node in a doubly linked list.",
              "C. O(log n)": "Logarithmic time complexity isn't applicable here.",
              "D. O(n^2)": "There's no nested iteration; it's linear traversal."
            }
        },
        {
            "question": "In a doubly linked list, what is the time complexity of deleting a node when you are given a pointer to the node to be deleted?",
            "options": ["A. O(1)", "B. O(n)", "C. O(log n)", "D. O(n^2)"],
            "answer": "A. O(1)",
            "explanation": "If you have a pointer to the node to be deleted in a doubly linked list, the deletion operation can be performed in constant time by adjusting the previous and next pointers.",
            "incorrect_options": {
              "B. O(n)": "This would be true if you didn't have the pointer to the node and had to search for it first.",
              "C. O(log n)": "This time complexity is not relevant for linked list operations.",
              "D. O(n^2)": "No nested loops are involved in this operation."
            }
        },
        {
            "question": "Consider the following pseudo-code. What will be the final value of sum after executing this function on the list 1 → 2 → 3 → 4?\nfunction computeSum(node):\n    sum = 0\n    while node != null:\n        sum = sum + node.data\n        node = node.next\n    return sum",
            "options": ["A. 0", "B. 10", "C. 7", "D. null"],
            "answer": "B. 10",
            "explanation": "The function traverses the list, summing the values of each node's data. The sum of 1 + 2 + 3 + 4 is 10.",
            "incorrect_options": {
              "A. 0": "This would be true if the list was empty or the code didn't update sum.",
              "C. 7": "Incorrect calculation.",
              "D. null": "The function returns a numeric value, not a reference."
            }
        },
        {
            "question": "What is the key advantage of a doubly linked list over a singly linked list?",
            "options": ["A. Uses less memory.", "B. Easier to reverse traversal.", "C. Faster to insert at the head.", "D. Easier to implement."],
            "answer": "B. Easier to reverse traversal.",
            "explanation": "Doubly linked lists allow reverse traversal using the prev pointer, which is not possible in a singly linked list.",
            "incorrect_options": {
              "A. Uses less memory": "Doubly linked lists use more memory due to the extra pointer (prev).",
              "C. Faster to insert at the head": "Both singly and doubly linked lists can insert at the head in O(1) time.",
              "D. Easier to implement": "Singly linked lists are generally simpler to implement."
            }
        },
        {
            "question": "What is the minimum number of pointers required to implement a singly linked list node?",
            "options": ["A. 1", "B. 2", "C. 3", "D. 4"],
            "answer": "A. 1",
            "explanation": "A singly linked list node requires only one pointer to the next node.",
            "incorrect_options": {
              "B. 2": "This applies to doubly linked lists, which require two pointers (next and prev).",
              "C. 3": "No common linked list structure requires 3 pointers in a single node.",
              "D. 4": "Incorrect, unnecessarily high number of pointers."
            }
        }
    ]
}
